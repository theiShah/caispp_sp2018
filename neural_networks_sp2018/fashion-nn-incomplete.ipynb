{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Portion: Fashion Item Classification\n",
    "\n",
    "* Dataset used: **Fashion MNIST** (28 x 28 grayscale images of fashion items)\n",
    "* Dataset size: 60,000 training samples, 10,000 test samples\n",
    "* Dataset source: https://github.com/zalandoresearch/fashion-mnist\n",
    "\n",
    "#### Classification Labels:\n",
    "Label | Description\n",
    ":--- | ---\n",
    "0 | T-shirt/top\n",
    "1 | Trouser\n",
    "2 | Pullover\n",
    "3 | Dress\n",
    "4 | Coat\n",
    "5 | Sandal\n",
    "6 | Shirt\n",
    "7 | Sneaker\n",
    "8 | Bag\n",
    "9 | Ankle boot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load in the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Fashion-MNIST dataset from 'fashion' folder\n",
    "\n",
    "from fashion import mnist_reader\n",
    "x_train, y_train = mnist_reader.load_mnist('fashion', kind='train')\n",
    "x_test, y_test = mnist_reader.load_mnist('fashion', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape is (60000, 784)\n",
      "Input type is <class 'numpy.ndarray'>\n",
      "Labels:\n",
      "[9 0 0 ... 3 0 5]\n",
      "Labels shape is(60000,)\n",
      "Labels type is <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Data exploration\n",
    "\n",
    "print(\"Inputs shape is \" + str(x_train.shape)) # 60,000 flattened image vectors (784 pixels long)\n",
    "print(\"Input type is \" + str(type(x_train)))\n",
    "print(\"Labels:\")\n",
    "print(y_train)\n",
    "print(\"Labels shape is\" + str(y_train.shape)) # 60,000 labels\n",
    "print(\"Labels type is \" + str(type(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numerical label to item description\n",
    "\n",
    "def to_description(label):\n",
    "    if label == 0: return \"T-shirt/top\"\n",
    "    elif label == 1: return \"Trouser\"\n",
    "    elif label == 2: return \"Pullover\"\n",
    "    elif label == 3: return \"Dress\"\n",
    "    elif label == 4: return \"Coat\"\n",
    "    elif label == 5: return \"Sandal\"\n",
    "    elif label == 6: return \"Shirt\"\n",
    "    elif label == 7: return \"Sneaker\"\n",
    "    elif label == 8: return \"Bag\"\n",
    "    elif label == 9: return \"Ankle boot\"\n",
    "    else: return \"Label not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  9\n",
      "Description:  Ankle boot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the training examples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_sample(sample_num):\n",
    "    flattened_vector = x_train[sample_num] # retrieve flattened vector\n",
    "    image_2d = np.reshape(flattened_vector, (28, 28)) # reshape to 28 x 28 grayscale image array\n",
    "    plt.imshow(image_2d, cmap = plt.get_cmap('gray')) # feed image into matplotlib\n",
    "    print(\"Label: \", y_train[sample_num]) # print actual label\n",
    "    print(\"Description: \", to_description(y_train[sample_num])) # print description\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "visualize_sample(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Pre-Processing\n",
    "1. Normalize the feature vectors/pixel values\n",
    "2. Categorize the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the X_train and X_test dataset pixel values to between 0-1\n",
    "\n",
    "# TODO: fill this in\n",
    "    # Hint: maximum pixel value is still 255\n",
    "#num_pixels = x_train.shape[1] * x_train.shape[2] # should be the right size \n",
    "#x_train_flattened = x_train.reshape(x_train.shape[0], num_pixels).astype('float32') \n",
    "#x_test_flattened = x_test.reshape(x_test.shape[0], num_pixels).astype('float32') \n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "# TODO: Use Keras to categorize the outputs (\"one-hot\" vectors)\n",
    "    # Use variable names: y_train_categorical, y_test_categorical\n",
    "    # hint: use the to_categorical() keras function to do this for you\n",
    "    \n",
    "y_train_categorical = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# let's see result of categorizing the outputs\n",
    "print(y_test_categorical[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create and Compile Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# TODO: fill this in\n",
    "# Feel free to experiment with different number of layers, number of neurons, activation functions, etc.\n",
    "    # Activation functions: https://keras.io/activations/\n",
    "    # Declaring Keras layers: https://keras.io/layers/core/\n",
    "    \n",
    "### Add 1st layer here. Remember that the input_dimension should match up with the input vector dimension!\n",
    "#model.add(Dense(units = 100, input_dim = 784, activation = 'relu'))\n",
    "\n",
    "### Add 2nd layer here.\n",
    "#model.add(Dense(units = 50, activation = 'sigmoid'))\n",
    "# Add final layer here. Make sure the last layer matches up the output vector dimension\n",
    "    # Hint: use softmax again to output classification probabilities\n",
    "model.add(Dense(units = 500, input_dim = 784, activation = 'relu'))\n",
    "model.add(Dense(units = 250, activation = 'relu'))\n",
    "#model.add(Dense(units = 15, activation = 'relu'))\n",
    "model.add(Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compile model\n",
    "    # Loss: categorical cross-entropy\n",
    "    # Optimizer: stochastic gradient descent\n",
    "        # Or: experiment with other optimizers? https://keras.io/optimizers/\n",
    "    # Metrics: accuracy\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2510      \n",
      "=================================================================\n",
      "Total params: 520,260\n",
      "Trainable params: 520,260\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "from keras_tqdm import TQDMNotebookCallback # TQDM: progress bars\n",
    "from keras.callbacks import TensorBoard # Tensorboard: training plots\n",
    "    \n",
    "# Clear any existing Tensorboard logs\n",
    "import shutil\n",
    "shutil.rmtree('./logs', ignore_errors=True)\n",
    "\n",
    "# Set up callback links to refer back to during training\n",
    "tensorboard = TensorBoard()\n",
    "callbacks_list = [TQDMNotebookCallback(), tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 31s 510us/step - loss: 0.5965 - acc: 0.7976\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 29s 491us/step - loss: 0.4361 - acc: 0.8461\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 30s 498us/step - loss: 0.3937 - acc: 0.8609\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 34s 575us/step - loss: 0.3657 - acc: 0.8699\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 48s 804us/step - loss: 0.3475 - acc: 0.8733\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 48s 798us/step - loss: 0.3313 - acc: 0.8802\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 45s 755us/step - loss: 0.3172 - acc: 0.8850\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 40s 673us/step - loss: 0.3075 - acc: 0.8880\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 44s 733us/step - loss: 0.2981 - acc: 0.8907\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 45s 743us/step - loss: 0.2896 - acc: 0.8943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc290258ba8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Fit model to training data\n",
    "    # Reserve some fraction of training data as validation data\n",
    "    # Pick number of epochs\n",
    "    # Pick a batch_size\n",
    "    # Pass in relevant callbacks_list from above\n",
    "    \n",
    "model.fit(x_train, y_train_categorical, epochs=10, batch_size=16)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 98us/step\n",
      "[0.3374591578722, 0.8801]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Evaluate model on test data\n",
    "\n",
    "# Use model.evaluate()\n",
    "# Also: open up the training logs in Tensorboard to check validation_loss for overfitting\n",
    "loss_and_metrics = model.evaluate(x_test, y_test_categorical, batch_size=128)\n",
    "\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final predictions testing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Compare actual class to predicted class\n",
    "def visualize_test_sample(test_sample_num):\n",
    "    \n",
    "    # Display actual image & label\n",
    "    flattened_vector = x_test[test_sample_num] # retrieve flattened vector\n",
    "    image_2d = np.reshape(flattened_vector, (28, 28)) # reshape to 28 x 28 grayscale image array\n",
    "    plt.imshow(image_2d, cmap = plt.get_cmap('gray')) # feed image into matplotlib\n",
    "    print(\"Actual Label: \", y_test[test_sample_num]) # print actual label\n",
    "    print(\"Actual Description: \", to_description(y_test[test_sample_num])) # print description\n",
    "    plt.show()\n",
    "    \n",
    "    # Print predicted label\n",
    "    test_sample = np.expand_dims(X_test[test_sample_num], axis=0) # pick out a one-sample \"batch\" to feed into model\n",
    "    predicted_scores = model.predict(test_sample) # outputted probabilities vector\n",
    "    print(\"Outputted scores: \", predicted_scores) # print predicted scores\n",
    "\n",
    "    predicted_class = np.argmax(predicted_scores) # pick the class with highest probability --> final prediction\n",
    "    print(\"Predicted Label: \", predicted_class) # print predicted classification\n",
    "    print(\"Predicted Description: \", to_description(predicted_class)) # print predicted label description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-da2a8f61699e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m visualize_test_sample(1\n\u001b[0m\u001b[1;32m      2\u001b[0m                      )\n",
      "\u001b[0;32m<ipython-input-14-8f77d44d967c>\u001b[0m in \u001b[0;36mvisualize_test_sample\u001b[0;34m(test_sample_num)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Display actual image & label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mflattened_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_sample_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# retrieve flattened vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mimage_2d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reshape to 28 x 28 grayscale image array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# feed image into matplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "visualize_test_sample(1\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:caispp]",
   "language": "python",
   "name": "conda-env-caispp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
