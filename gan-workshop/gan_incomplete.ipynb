{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# All the necesssary imports.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Activation, Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras.datasets import mnist\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# Normalize to [-1, 1] (easier to work with)\n",
    "x_train = (x_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "# For the sake of time don't work with the entire dataset.\n",
    "x_train = x_train[:10000]\n",
    "y_train = x_train[:10000]\n",
    "\n",
    "# Flatten the data.\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot out a sample image (reshaped to 28 x 28)\n",
    "plt.imshow(x_train[0].reshape(28, 28), cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many noise dimensions our generator should take in\n",
    "NOISE_DIM = 100 # Feel free to tweak this and see what changes\n",
    "\n",
    "# Define the generator.\n",
    "# The generator should have the following layers.\n",
    "# Fully connected from # noise dimensions to 256\n",
    "# LeakyReLU (alpha = 0.2) (what is leaky relu? https://cdn-images-1.medium.com/max/1600/1*A_Bzn0CjUgOXtPCJKnKLqA.jpeg)\n",
    "# Fully connected from 256 to 512\n",
    "# LeakyReLU (alpha = 0.2)\n",
    "# Fully connected from 512 to 1024\n",
    "# LeakyReLU (alpha = 0.2)\n",
    "# Fully connected from 1024 to 784 (28*28)\n",
    "# tanh (To normalize our output from -1 to 1)\n",
    "\n",
    "def generator():\n",
    "    ###################################\n",
    "    #TODO: Implement\n",
    "    model = Sequential()\n",
    "    \n",
    "    # How to add leaky relu\n",
    "    #model.add(LeakyReLU())\n",
    "    # (We'll give you this first layer. Keep the initializer as is -- it works better than the default)\n",
    "    # (You can also keep initializers default for the rest of the layers)\n",
    "    model.add(Dense(256, input_dim=NOISE_DIM, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "   \n",
    "    # Add the rest of the layers\n",
    "    model.add(LeakyReLU(alpha = 0.2))\n",
    "    model.add(Dense(512, input_dim=256))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(1024, input_dim=512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dense(784, input_dim=1024))\n",
    "    \n",
    "    return model\n",
    "    ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the discriminator here.\n",
    "# Should have the following layers\n",
    "# Fully connected from 784 (28*28) to 1024\n",
    "# LeakyReLU (alpha = 0.2)\n",
    "# Dropout with p = 0.3\n",
    "# Fully connected from 1024 to 512\n",
    "# LeakyReLU (alpha = 0.2)\n",
    "# Dropout with p = 0.3\n",
    "# Fully connected from 512 to 256\n",
    "# LeakyReLU (alpha = 0.2)\n",
    "# Dropout with p = 0.3\n",
    "# Fully connected from 256 to 1\n",
    "# sigmoid (to get our probability)\n",
    "\n",
    "def discriminator():\n",
    "    model = Sequential()\n",
    "    # (We'll give you this first layer. Keep the initializer as is -- it works better than the default)\n",
    "    model.add(Dense(1024, input_dim=784, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
    "    \n",
    "    # Add the rest of the layers\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, input_dim=1024))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(256, input_dim=512))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, input_dim=256))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    \n",
    "    return model\n",
    "    ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed the generated image into the discriminator. \n",
    "# Weâ€™ll use this to train our generator end-to-end later on, \n",
    "    # while leaving the discriminator weights untouched \n",
    "# Hint: we can add existing Sequential() models to new models, just like we can with any other layer.\n",
    "    # The parameters are then \"passed by reference,\" so that they use the same internal weights.\n",
    "\n",
    "# Remember that we are not updating our discriminator in this step. \n",
    "    # (We'll train the discriminator separately.)\n",
    "# Please refer to \n",
    "    # https://keras.io/getting-started/faq/#how-can-i-freeze-keras-layers\n",
    "    # on how to \"freeze\" or set layers to be untrainable in keras.\n",
    "# We can call this \"freeze\" operation on an entire model.\n",
    "\n",
    "def combine(generator, discriminator):\n",
    "    ###################################\n",
    "    # TODO: Implement\n",
    "    #for layer in discriminator.layers:\n",
    "     #   layer.trainable=False\n",
    "    discriminator.trainable=False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    return model\n",
    "    ###################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the discriminator, generator, and full GAN. \n",
    "\n",
    "# Use this optimizer for each of the models\n",
    "opt = Adam(lr=.0002, beta_1=0.5)\n",
    "\n",
    "#############################################\n",
    "# TODO: Compile generator and discriminator\n",
    "g = generator()\n",
    "# generator.compile(optimizer=opt, loss='categorical_crossentropy')\n",
    "# Discriminator\n",
    "# d = None\n",
    "d = discriminator()\n",
    "d.compile(optimizer=opt, loss='categorical_crossentropy')\n",
    "# Full gan\n",
    "# gd = None\n",
    "gan = combine(g, d)\n",
    "gan.compile(optimizer=opt, loss='categorical_crossentropy')\n",
    "#############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display sample from the network\n",
    "def disp_sample(g):\n",
    "    noise = np.random.uniform(-1, 1, size=(batch_size, NOISE_DIM))\n",
    "    generated_images = g.predict(noise, verbose=0)\n",
    "    show_im = generated_images[0]\n",
    "    show_im = (show_im + 1) / 2.0\n",
    "    show_im = show_im.reshape(28, 28)\n",
    "    plt.imshow(show_im, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (256, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-4a7574c15170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Update d.trainable as necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Now, set d.trainable to False again to get ready for the end-to-end generator training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# (We want to hold the discriminator constant while we're training the generator. See below.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/caispp/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1065\u001b[0m         return self.model.train_on_batch(x, y,\n\u001b[1;32m   1066\u001b[0m                                          \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m                                          class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     def test_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/caispp/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1875\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1878\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/caispp/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1491\u001b[0m         _check_loss_and_target_compatibility(y,\n\u001b[1;32m   1492\u001b[0m                                              \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_loss_fns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1493\u001b[0;31m                                              self._feed_output_shapes)\n\u001b[0m\u001b[1;32m   1494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/caispp/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_check_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 raise ValueError(\n\u001b[1;32m    255\u001b[0m                     \u001b[0;34m'You are passing a target array of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                     \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m                     \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (256, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "# Keep this. \n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(100):\n",
    "    print('Epoch #%d' % epoch)\n",
    "    \n",
    "    # Generate an image and display it.\n",
    "    disp_sample(g)\n",
    "    \n",
    "    num_batches = int(x_train.shape[0] / batch_size)\n",
    "    all_g_loss = []\n",
    "    all_d_loss = []\n",
    "    for i in range(num_batches):\n",
    "        #######################################################\n",
    "        #TODO: Complete a training iteration\n",
    "        # Generate noise.\n",
    "        noise = np.random.uniform(-1, 1, size=(batch_size, NOISE_DIM))\n",
    "        \n",
    "        # Generate images from the noise using the generator.\n",
    "            # See 'predict()': https://keras.io/models/sequential/\n",
    "        generated_images = _generator.predict(noise)\n",
    "        \n",
    "        # Grab the image batch for this iteration. \n",
    "        real_images = x_train[i * batch_size: (i+1) * batch_size]\n",
    "        \n",
    "        ### Train the discriminator using the generated images and the real images ###\n",
    "        \n",
    "        # Contains the real and fake images. (Concatenate!)\n",
    "            # https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.concatenate.html\n",
    "        X = np.concatenate((generated_images, real_images))\n",
    "        \n",
    "        # Labels if the sample is real (1) or not real (0). \n",
    "            # Numpy 'ones' function: https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ones.html\n",
    "            # 'zeros': https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.zeros.html\n",
    "        y = np.ones((batch_size * 2))\n",
    "        \n",
    "        # Remember that for this line, the discriminator has to have d.trainable = True!\n",
    "            # Update d.trainable as necessary\n",
    "        d.trainable = True\n",
    "        d_loss = d.train_on_batch(X, y)\n",
    "        # Now, set d.trainable to False again to get ready for the end-to-end generator training\n",
    "            # (We want to hold the discriminator constant while we're training the generator. See below.)\n",
    "        d.trainable = False\n",
    "        # Generate more noise to feed into the full gan network to train the generative portion. \n",
    "        noise = noise = np.random.uniform(-1, 1, size=(batch_size, NOISE_DIM))\n",
    "\n",
    "        \n",
    "        # Get the g_loss (fill in the ... part between the parantheses)\n",
    "            # Hint: we want the final output to be 1 (indicating that the discriminator was fooled),\n",
    "            # So the labels should be all 1's. \n",
    "            # Then, since the discriminator weights are fixed,\n",
    "            # the generator weights will have to adjust so that the final outputs will be closer to 1 \n",
    "            # (i.e. are are producing more realistic images).\n",
    "        g_loss = dg.train_on_batch(...)\n",
    "        \n",
    "        # For getting the averages of each epoch\n",
    "        all_d_loss.append(d_loss)\n",
    "        all_g_loss.append(g_loss)\n",
    "        \n",
    "        #######################################################\n",
    "    print('%i D: %.4f, G: %.4f' % (epoch, np.mean(all_d_loss), np.mean(all_g_loss)))\n",
    "\n",
    "#########################################################################################\n",
    "# Why is my generative loss oscillating???   \n",
    "# Don't worry this is normal as the generator is oscillating between possible solutions\n",
    "#########################################################################################\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
